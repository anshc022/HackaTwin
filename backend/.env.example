# Local AI Configuration (Choose one)
LOCAL_AI_TYPE=ollama                    # ollama, localai, lmstudio
LOCAL_AI_URL=http://localhost:11434     # Ollama default port
LOCAL_AI_MODEL=llama3.2:3b             # Lightweight model
AI_FALLBACK=true                        # Use fallback if local AI fails

# Alternative Local AI Configurations:
# For LocalAI: LOCAL_AI_URL=http://localhost:8080
# For LM Studio: LOCAL_AI_URL=http://localhost:1234

# SendGrid Email Configuration
SENDGRID_API_KEY=your_sendgrid_api_key_here
FROM_EMAIL=your_email@domain.com

# Slack Configuration
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token
SLACK_CHANNEL_ID=your_channel_id

# Discord Configuration
DISCORD_LINK=https://discord.gg/your_invite_link

# Environment
ENVIRONMENT=development
